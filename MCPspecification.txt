Specification
Architecture
Architecture

The Model Context Protocol (MCP) follows a client-host-server architecture where each host can run multiple client instances. This architecture enables users to integrate AI capabilities across applications while maintaining clear security boundaries and isolating concerns. Built on JSON-RPC, MCP provides a stateful session protocol focused on context exchange and sampling coordination between clients and servers.
Core Components

Internet

Local machine

Application Host Process

Server 3
External APIs

Remote
Resource C

Server 1
Files & Git

Server 2
Database

Local
Resource A

Local
Resource B

Host

Client 1

Client 2

Client 3

Host

The host process acts as the container and coordinator:

    Creates and manages multiple client instances
    Controls client connection permissions and lifecycle
    Enforces security policies and consent requirements
    Handles user authorization decisions
    Coordinates AI/LLM integration and sampling
    Manages context aggregation across clients

Clients

Each client is created by the host and maintains an isolated server connection:

    Establishes one stateful session per server
    Handles protocol negotiation and capability exchange
    Routes protocol messages bidirectionally
    Manages subscriptions and notifications
    Maintains security boundaries between servers

A host application creates and manages multiple clients, with each client having a 1:1 relationship with a particular server.
Servers

Servers provide specialized context and capabilities:

    Expose resources, tools and prompts via MCP primitives
    Operate independently with focused responsibilities
    Request sampling through client interfaces
    Must respect security constraints
    Can be local processes or remote services

Design Principles

MCP is built on several key design principles that inform its architecture and implementation:

    Servers should be extremely easy to build
        Host applications handle complex orchestration responsibilities
        Servers focus on specific, well-defined capabilities
        Simple interfaces minimize implementation overhead
        Clear separation enables maintainable code

    Servers should be highly composable
        Each server provides focused functionality in isolation
        Multiple servers can be combined seamlessly
        Shared protocol enables interoperability
        Modular design supports extensibility

    Servers should not be able to read the whole conversation, nor “see into” other servers
        Servers receive only necessary contextual information
        Full conversation history stays with the host
        Each server connection maintains isolation
        Cross-server interactions are controlled by the host
        Host process enforces security boundaries

    Features can be added to servers and clients progressively
        Core protocol provides minimal required functionality
        Additional capabilities can be negotiated as needed
        Servers and clients evolve independently
        Protocol designed for future extensibility
        Backwards compatibility is maintained

Message Types

MCP defines three core message types based on JSON-RPC 2.0:

    Requests: Bidirectional messages with method and parameters expecting a response
    Responses: Successful results or errors matching specific request IDs
    Notifications: One-way messages requiring no response

Each message type follows the JSON-RPC 2.0 specification for structure and delivery semantics.
Capability Negotiation

The Model Context Protocol uses a capability-based negotiation system where clients and servers explicitly declare their supported features during initialization. Capabilities determine which protocol features and primitives are available during a session.

    Servers declare capabilities like resource subscriptions, tool support, and prompt templates
    Clients declare capabilities like sampling support and notification handling
    Both parties must respect declared capabilities throughout the session
    Additional capabilities can be negotiated through extensions to the protocol

Server

Client

Host

Server

Client

Host

Active Session with Negotiated Features

loop[Client Requests]

loop[Server Requests]

loop[Notifications]Initialize client

Initialize session with capabilities

Respond with supported capabilities

User- or model-initiated action

Request (tools/resources)

Response

Update UI or respond to model

Request (sampling)

Forward to AI

AI response

Response

Resource updates

Status changes

Terminate

End session

Each capability unlocks specific protocol features for use during the session. For example:

    Implemented server features must be advertised in the server’s capabilities
    Emitting resource subscription notifications requires the server to declare subscription support
    Tool invocation requires the server to declare tool capabilities
    Sampling requires the client to declare support in its capabilities

This capability negotiation ensures clients and servers have a clear understanding of supported functionality while maintaining protocol extensibility.

Base Protocol
Protocol Revision: 2024-11-05

All messages between MCP clients and servers MUST follow the JSON-RPC 2.0 specification. The protocol defines three fundamental types of messages:
Type	Description	Requirements
Requests	Messages sent to initiate an operation	Must include unique ID and method name
Responses	Messages sent in reply to requests	Must include same ID as request
Notifications	One-way messages with no reply	Must not include an ID

Responses are further sub-categorized as either successful results or errors. Results can follow any JSON object structure, while errors must include an error code and message at minimum.
Protocol Layers

The Model Context Protocol consists of several key components that work together:

    Base Protocol: Core JSON-RPC message types
    Lifecycle Management: Connection initialization, capability negotiation, and session control
    Server Features: Resources, prompts, and tools exposed by servers
    Client Features: Sampling and root directory lists provided by clients
    Utilities: Cross-cutting concerns like logging and argument completion

All implementations MUST support the base protocol and lifecycle management components. Other components MAY be implemented based on the specific needs of the application.

These protocol layers establish clear separation of concerns while enabling rich interactions between clients and servers. The modular design allows implementations to support exactly the features they need.

See the following pages for more details on the different components:
Lifecycle
Resources
Prompts
Tools
Logging
Sampling
Auth

Authentication and authorization are not currently part of the core MCP specification, but we are considering ways to introduce them in future. Join us in GitHub Discussions to help shape the future of the protocol!

Clients and servers MAY negotiate their own custom authentication and authorization strategies.
Schema

The full specification of the protocol is defined as a TypeScript schema. This is the source of truth for all protocol messages and structures.

There is also a JSON Schema, which is automatically generated from the TypeScript source of truth, for use with various automated tooling.

Specification
Base Protocol
Base Protocol
Protocol Revision: 2024-11-05

All messages between MCP clients and servers MUST follow the JSON-RPC 2.0 specification. The protocol defines three fundamental types of messages:
Type	Description	Requirements
Requests	Messages sent to initiate an operation	Must include unique ID and method name
Responses	Messages sent in reply to requests	Must include same ID as request
Notifications	One-way messages with no reply	Must not include an ID

Responses are further sub-categorized as either successful results or errors. Results can follow any JSON object structure, while errors must include an error code and message at minimum.
Protocol Layers

The Model Context Protocol consists of several key components that work together:

    Base Protocol: Core JSON-RPC message types
    Lifecycle Management: Connection initialization, capability negotiation, and session control
    Server Features: Resources, prompts, and tools exposed by servers
    Client Features: Sampling and root directory lists provided by clients
    Utilities: Cross-cutting concerns like logging and argument completion

All implementations MUST support the base protocol and lifecycle management components. Other components MAY be implemented based on the specific needs of the application.

These protocol layers establish clear separation of concerns while enabling rich interactions between clients and servers. The modular design allows implementations to support exactly the features they need.

See the following pages for more details on the different components:
Lifecycle
Resources
Prompts
Tools
Logging
Sampling
Auth

Authentication and authorization are not currently part of the core MCP specification, but we are considering ways to introduce them in future. Join us in GitHub Discussions to help shape the future of the protocol!

Clients and servers MAY negotiate their own custom authentication and authorization strategies.
Schema

The full specification of the protocol is defined as a TypeScript schema. This is the source of truth for all protocol messages and structures.

There is also a JSON Schema, which is automatically generated from the TypeScript source of truth, for use with various automated tooling.

Specification
Base Protocol
Messages
Messages
Protocol Revision: 2024-11-05

All messages in MCP MUST follow the JSON-RPC 2.0 specification. The protocol defines three types of messages:
Requests

Requests are sent from the client to the server or vice versa.

{
  jsonrpc: "2.0";
  id: string | number;
  method: string;
  params?: {
    [key: string]: unknown;
  };
}

    Requests MUST include a string or integer ID.
    Unlike base JSON-RPC, the ID MUST NOT be null.
    The request ID MUST NOT have been previously used by the requestor within the same session.

Responses

Responses are sent in reply to requests.

{
  jsonrpc: "2.0";
  id: string | number;
  result?: {
    [key: string]: unknown;
  }
  error?: {
    code: number;
    message: string;
    data?: unknown;
  }
}

    Responses MUST include the same ID as the request they correspond to.
    Either a result or an error MUST be set. A response MUST NOT set both.
    Error codes MUST be integers.

Notifications

Notifications are sent from the client to the server or vice versa. They do not expect a response.

{
  jsonrpc: "2.0";
  method: string;
  params?: {
    [key: string]: unknown;
  };
}

    Notifications MUST NOT include an ID.
	
	Specification
Base Protocol
Lifecycle
Lifecycle
Protocol Revision: 2024-11-05

The Model Context Protocol (MCP) defines a rigorous lifecycle for client-server connections that ensures proper capability negotiation and state management.

    Initialization: Capability negotiation and protocol version agreement
    Operation: Normal protocol communication
    Shutdown: Graceful termination of the connection

Server

Client

Server

Client

Initialization Phase

Operation Phase

Normal protocol operations

Shutdown

Connection closedinitialize request

initialize response

initialized notification

Disconnect

Lifecycle Phases
Initialization

The initialization phase MUST be the first interaction between client and server. During this phase, the client and server:

    Establish protocol version compatibility
    Exchange and negotiate capabilities
    Share implementation details

The client MUST initiate this phase by sending an initialize request containing:

    Protocol version supported
    Client capabilities
    Client implementation information

{
  "jsonrpc": "2.0",
  "id": 1,
  "method": "initialize",
  "params": {
    "protocolVersion": "2024-11-05",
    "capabilities": {
      "roots": {
        "listChanged": true
      },
      "sampling": {}
    },
    "clientInfo": {
      "name": "ExampleClient",
      "version": "1.0.0"
    }
  }
}

The server MUST respond with its own capabilities and information:

{
  "jsonrpc": "2.0",
  "id": 1,
  "result": {
    "protocolVersion": "2024-11-05",
    "capabilities": {
      "logging": {},
      "prompts": {
        "listChanged": true
      },
      "resources": {
        "subscribe": true,
        "listChanged": true
      },
      "tools": {
        "listChanged": true
      }
    },
    "serverInfo": {
      "name": "ExampleServer",
      "version": "1.0.0"
    }
  }
}

After successful initialization, the client MUST send an initialized notification to indicate it is ready to begin normal operations:

{
  "jsonrpc": "2.0",
  "method": "notifications/initialized"
}

    The client SHOULD NOT send requests other than pings before the server has responded to the initialize request.
    The server SHOULD NOT send requests other than pings and logging before receiving the initialized notification.

Version Negotiation

In the initialize request, the client MUST send a protocol version it supports. This SHOULD be the latest version supported by the client.

If the server supports the requested protocol version, it MUST respond with the same version. Otherwise, the server MUST respond with another protocol version it supports. This SHOULD be the latest version supported by the server.

If the client does not support the version in the server’s response, it SHOULD disconnect.
Capability Negotiation

Client and server capabilities establish which optional protocol features will be available during the session.

Key capabilities include:
Category	Capability	Description
Client	roots	Ability to provide filesystem roots
Client	sampling	Support for LLM sampling requests
Client	experimental	Describes support for non-standard experimental features
Server	prompts	Offers prompt templates
Server	resources	Provides readable resources
Server	tools	Exposes callable tools
Server	logging	Emits structured log messages
Server	experimental	Describes support for non-standard experimental features

Capability objects can describe sub-capabilities like:

    listChanged: Support for list change notifications (for prompts, resources, and tools)
    subscribe: Support for subscribing to individual items’ changes (resources only)

Operation

During the operation phase, the client and server exchange messages according to the negotiated capabilities.

Both parties SHOULD:

    Respect the negotiated protocol version
    Only use capabilities that were successfully negotiated

Shutdown

During the shutdown phase, one side (usually the client) cleanly terminates the protocol connection. No specific shutdown messages are defined—instead, the underlying transport mechanism should be used to signal connection termination:
stdio

For the stdio transport, the client SHOULD initiate shutdown by:

    First, closing the input stream to the child process (the server)
    Waiting for the server to exit, or sending SIGTERM if the server does not exit within a reasonable time
    Sending SIGKILL if the server does not exit within a reasonable time after SIGTERM

The server MAY initiate shutdown by closing its output stream to the client and exiting.
HTTP

For HTTP transports, shutdown is indicated by closing the associated HTTP connection(s).
Error Handling

Implementations SHOULD be prepared to handle these error cases:

    Protocol version mismatch
    Failure to negotiate required capabilities
    Initialize request timeout
    Shutdown timeout

Implementations SHOULD implement appropriate timeouts for all requests, to prevent hung connections and resource exhaustion.

Example initialization error:

{
  "jsonrpc": "2.0",
  "id": 1,
  "error": {
    "code": -32602,
    "message": "Unsupported protocol version",
    "data": {
      "supported": ["2024-11-05"],
      "requested": "1.0.0"
    }
  }
}

Transports
Protocol Revision: 2024-11-05

MCP currently defines two standard transport mechanisms for client-server communication:

    stdio, communication over standard in and standard out
    HTTP with Server-Sent Events (SSE)

Clients SHOULD support stdio whenever possible.

It is also possible for clients and servers to implement custom transports in a pluggable fashion.
stdio

In the stdio transport:

    The client launches the MCP server as a subprocess.
    The server receives JSON-RPC messages on its standard input (stdin) and writes responses to its standard output (stdout).
    Messages are delimited by newlines, and MUST NOT contain embedded newlines.
    The server MAY write UTF-8 strings to its standard error (stderr) for logging purposes. Clients MAY capture, forward, or ignore this logging.
    The server MUST NOT write anything to its stdout that is not a valid MCP message.
    The client MUST NOT write anything to the server’s stdin that is not a valid MCP message.

Server Process

Client

Server Process

Client

loop[Message Exchange]Launch subprocess

Write to stdin

Write to stdout

Optional logs on stderr

Close stdin, terminate subprocess

HTTP with SSE

In the SSE transport, the server operates as an independent process that can handle multiple client connections.

The server MUST provide two endpoints:

    An SSE endpoint, for clients to establish a connection and receive messages from the server
    A regular HTTP POST endpoint for clients to send messages to the server

When a client connects, the server MUST send an endpoint event containing a URI for the client to use for sending messages. All subsequent client messages MUST be sent as HTTP POST requests to this endpoint.

Server messages are sent as SSE message events, with the message content encoded as JSON in the event data.

Server

Client

Server

Client

loop[Message Exchange]Open SSE connection

endpoint event

HTTP POST messages

SSE message events

Close SSE connection

Custom Transports

Clients and servers MAY implement additional custom transport mechanisms to suit their specific needs. The protocol is transport-agnostic and can be implemented over any communication channel that supports bidirectional message exchange.

Implementers who choose to support custom transports MUST ensure they preserve the JSON-RPC message format and lifecycle requirements defined by MCP. Custom transports SHOULD document their specific connection establishment and message exchange patterns to aid interoperability.

Versioning

The Model Context Protocol uses string-based version identifiers following the format YYYY-MM-DD, to indicate the last date backwards incompatible changes were made.

The current protocol version is 2024-11-05. See all revisions.
The protocol version will not be incremented when the protocol is updated, as long as the changes maintain backwards compatibility. This allows for incremental improvements while preserving interoperability.

Version negotiation happens during initialization. Clients and servers MAY support multiple protocol versions simultaneously, but they MUST agree on a single version to use for the session.

The protocol provides appropriate error handling if version negotiation fails, allowing clients to gracefully terminate connections when they cannot find a version compatible with the server.

Utilities
Protocol Revision: 2024-11-05

These optional features enhance the base protocol functionality with various utilities.
Ping
Cancellation
Progress

Ping
Protocol Revision: 2024-11-05

The Model Context Protocol includes an optional ping mechanism that allows either party to verify that their counterpart is still responsive and the connection is alive.
Overview

The ping functionality is implemented through a simple request/response pattern. Either the client or server can initiate a ping by sending a ping request.
Message Format

A ping request is a standard JSON-RPC request with no parameters:

{
  "jsonrpc": "2.0",
  "id": "123",
  "method": "ping"
}

Behavior Requirements

    The receiver MUST respond promptly with an empty response:

{
  "jsonrpc": "2.0",
  "id": "123",
  "result": {}
}

    If no response is received within a reasonable timeout period, the sender MAY:
        Consider the connection stale
        Terminate the connection
        Attempt reconnection procedures

Usage Patterns

Receiver

Sender

Receiver

Sender

ping request

empty response

Implementation Considerations

    Implementations SHOULD periodically issue pings to detect connection health
    The frequency of pings SHOULD be configurable
    Timeouts SHOULD be appropriate for the network environment
    Excessive pinging SHOULD be avoided to reduce network overhead

Error Handling

    Timeouts SHOULD be treated as connection failures
    Multiple failed pings MAY trigger connection reset
    Implementations SHOULD log ping failures for diagnostics
	
	Cancellation
Protocol Revision: 2024-11-05

The Model Context Protocol (MCP) supports optional cancellation of in-progress requests through notification messages. Either side can send a cancellation notification to indicate that a previously-issued request should be terminated.
Cancellation Flow

When a party wants to cancel an in-progress request, it sends a notifications/cancelled notification containing:

    The ID of the request to cancel
    An optional reason string that can be logged or displayed

{
  "jsonrpc": "2.0",
  "method": "notifications/cancelled",
  "params": {
    "requestId": "123",
    "reason": "User requested cancellation"
  }
}

Behavior Requirements

    Cancellation notifications MUST only reference requests that:
        Were previously issued in the same direction
        Are believed to still be in-progress
    The initialize request MUST NOT be cancelled by clients
    Receivers of cancellation notifications SHOULD:
        Stop processing the cancelled request
        Free associated resources
        Not send a response for the cancelled request
    Receivers MAY ignore cancellation notifications if:
        The referenced request is unknown
        Processing has already completed
        The request cannot be cancelled
    The sender of the cancellation notification SHOULD ignore any response to the request that arrives afterward

Timing Considerations

Due to network latency, cancellation notifications may arrive after request processing has completed, and potentially after a response has already been sent.

Both parties MUST handle these race conditions gracefully:

Server

Client

Server

Client

Processing starts

Processing may havecompleted beforecancellation arrives

Stop processing

alt​[If notcompleted]Request (ID: 123)

notifications/cancelled (ID: 123)

Implementation Notes

    Both parties SHOULD log cancellation reasons for debugging
    Application UIs SHOULD indicate when cancellation is requested

Error Handling

Invalid cancellation notifications SHOULD be ignored:

    Unknown request IDs
    Already completed requests
    Malformed notifications

This maintains the “fire and forget” nature of notifications while allowing for race conditions in asynchronous communication.

Progress
Protocol Revision: 2024-11-05

The Model Context Protocol (MCP) supports optional progress tracking for long-running operations through notification messages. Either side can send progress notifications to provide updates about operation status.
Progress Flow

When a party wants to receive progress updates for a request, it includes a progressToken in the request metadata.

    Progress tokens MUST be a string or integer value
    Progress tokens can be chosen by the sender using any means, but MUST be unique across all active requests.

{
  "jsonrpc": "2.0",
  "id": 1,
  "method": "some_method",
  "params": {
    "_meta": {
      "progressToken": "abc123"
    }
  }
}

The receiver MAY then send progress notifications containing:

    The original progress token
    The current progress value so far
    An optional “total” value

{
  "jsonrpc": "2.0",
  "method": "notifications/progress",
  "params": {
    "progressToken": "abc123",
    "progress": 50,
    "total": 100
  }
}

    The progress value MUST increase with each notification, even if the total is unknown.
    The progress and the total values MAY be floating point.

Behavior Requirements

    Progress notifications MUST only reference tokens that:
        Were provided in an active request
        Are associated with an in-progress operation

    Receivers of progress requests MAY:
        Choose not to send any progress notifications
        Send notifications at whatever frequency they deem appropriate
        Omit the total value if unknown

Receiver

Sender

Receiver

Sender

Request with progress token

Progress updates

loop[Progress Updates]

Operation completeMethod request with progressToken

Progress notification (0.2/1.0)

Progress notification (0.6/1.0)

Progress notification (1.0/1.0)

Method response

Implementation Notes

    Senders and receivers SHOULD track active progress tokens
    Both parties SHOULD implement rate limiting to prevent flooding
    Progress notifications MUST stop after completion
	
	Server Features
Protocol Revision: 2024-11-05

Servers provide the fundamental building blocks for adding context to language models via MCP. These primitives enable rich interactions between clients, servers, and language models:

    Prompts: Pre-defined templates or instructions that guide language model interactions
    Resources: Structured data or content that provides additional context to the model
    Tools: Executable functions that allow models to perform actions or retrieve information

Each primitive can be summarized in the following control hierarchy:
Primitive	Control	Description	Example
Prompts	User-controlled	Interactive templates invoked by user choice	Slash commands, menu options
Resources	Application-controlled	Contextual data attached and managed by the client	File contents, git history
Tools	Model-controlled	Functions exposed to the LLM to take actions	API POST requests, file writing

Explore these key primitives in more detail below:
Prompts
Resources
Tools

Prompts
Protocol Revision: 2024-11-05

The Model Context Protocol (MCP) provides a standardized way for servers to expose prompt templates to clients. Prompts allow servers to provide structured messages and instructions for interacting with language models. Clients can discover available prompts, retrieve their contents, and provide arguments to customize them.
User Interaction Model

Prompts are designed to be user-controlled, meaning they are exposed from servers to clients with the intention of the user being able to explicitly select them for use.

Typically, prompts would be triggered through user-initiated commands in the user interface, which allows users to naturally discover and invoke available prompts.

For example, as slash commands:

Example of prompt exposed as slash command

However, implementors are free to expose prompts through any interface pattern that suits their needs—the protocol itself does not mandate any specific user interaction model.
Capabilities

Servers that support prompts MUST declare the prompts capability during initialization:

{
  "capabilities": {
    "prompts": {
      "listChanged": true
    }
  }
}

listChanged indicates whether the server will emit notifications when the list of available prompts changes.
Protocol Messages
Listing Prompts

To retrieve available prompts, clients send a prompts/list request. This operation supports pagination.

Request:

{
  "jsonrpc": "2.0",
  "id": 1,
  "method": "prompts/list",
  "params": {
    "cursor": "optional-cursor-value"
  }
}

Response:

{
  "jsonrpc": "2.0",
  "id": 1,
  "result": {
    "prompts": [
      {
        "name": "code_review",
        "description": "Asks the LLM to analyze code quality and suggest improvements",
        "arguments": [
          {
            "name": "code",
            "description": "The code to review",
            "required": true
          }
        ]
      }
    ],
    "nextCursor": "next-page-cursor"
  }
}

Getting a Prompt

To retrieve a specific prompt, clients send a prompts/get request. Arguments may be auto-completed through the completion API.

Request:

{
  "jsonrpc": "2.0",
  "id": 2,
  "method": "prompts/get",
  "params": {
    "name": "code_review",
    "arguments": {
      "code": "def hello():\n    print('world')"
    }
  }
}

Response:

{
  "jsonrpc": "2.0",
  "id": 2,
  "result": {
    "description": "Code review prompt",
    "messages": [
      {
        "role": "user",
        "content": {
          "type": "text",
          "text": "Please review this Python code:\ndef hello():\n    print('world')"
        }
      }
    ]
  }
}

List Changed Notification

When the list of available prompts changes, servers that declared the listChanged capability SHOULD send a notification:

{
  "jsonrpc": "2.0",
  "method": "notifications/prompts/list_changed"
}

Message Flow

Server

Client

Server

Client

Discovery

Usage

Changes

opt[listChanged]prompts/list

List of prompts

prompts/get

Prompt content

prompts/list_changed

prompts/list

Updated prompts

Data Types
Prompt

A prompt definition includes:

    name: Unique identifier for the prompt
    description: Optional human-readable description
    arguments: Optional list of arguments for customization

PromptMessage

Messages in a prompt can contain:

    role: Either “user” or “assistant” to indicate the speaker
    content: One of the following content types:

Text Content

Text content represents plain text messages:

{
  "type": "text",
  "text": "The text content of the message"
}

This is the most common content type used for natural language interactions.
Image Content

Image content allows including visual information in messages:

{
  "type": "image",
  "data": "base64-encoded-image-data",
  "mimeType": "image/png"
}

The image data MUST be base64-encoded and include a valid MIME type. This enables multi-modal interactions where visual context is important.
Embedded Resources

Embedded resources allow referencing server-side resources directly in messages:

{
  "type": "resource",
  "resource": {
    "uri": "resource://example",
    "mimeType": "text/plain",
    "text": "Resource content"
  }
}

Resources can contain either text or binary (blob) data and MUST include:

    A valid resource URI
    The appropriate MIME type
    Either text content or base64-encoded blob data

Embedded resources enable prompts to seamlessly incorporate server-managed content like documentation, code samples, or other reference materials directly into the conversation flow.
Error Handling

Servers SHOULD return standard JSON-RPC errors for common failure cases:

    Invalid prompt name: -32602 (Invalid params)
    Missing required arguments: -32602 (Invalid params)
    Internal errors: -32603 (Internal error)

Implementation Considerations

    Servers SHOULD validate prompt arguments before processing
    Clients SHOULD handle pagination for large prompt lists
    Both parties SHOULD respect capability negotiation

Security

Implementations MUST carefully validate all prompt inputs and outputs to prevent injection attacks or unauthorized access to resources.


Resources
Protocol Revision: 2024-11-05

The Model Context Protocol (MCP) provides a standardized way for servers to expose resources to clients. Resources allow servers to share data that provides context to language models, such as files, database schemas, or application-specific information. Each resource is uniquely identified by a URI.
User Interaction Model

Resources in MCP are designed to be application-driven, with host applications determining how to incorporate context based on their needs.

For example, applications could:

    Expose resources through UI elements for explicit selection, in a tree or list view
    Allow the user to search through and filter available resources
    Implement automatic context inclusion, based on heuristics or the AI model’s selection

Example of resource context picker

However, implementations are free to expose resources through any interface pattern that suits their needs—the protocol itself does not mandate any specific user interaction model.
Capabilities

Servers that support resources MUST declare the resources capability:

{
  "capabilities": {
    "resources": {
      "subscribe": true,
      "listChanged": true
    }
  }
}

The capability supports two optional features:

    subscribe: whether the client can subscribe to be notified of changes to individual resources.
    listChanged: whether the server will emit notifications when the list of available resources changes.

Both subscribe and listChanged are optional—servers can support neither, either, or both:

{
  "capabilities": {
    "resources": {}  // Neither feature supported
  }
}

{
  "capabilities": {
    "resources": {
      "subscribe": true  // Only subscriptions supported
    }
  }
}

{
  "capabilities": {
    "resources": {
      "listChanged": true  // Only list change notifications supported
    }
  }
}

Protocol Messages
Listing Resources

To discover available resources, clients send a resources/list request. This operation supports pagination.

Request:

{
  "jsonrpc": "2.0",
  "id": 1,
  "method": "resources/list",
  "params": {
    "cursor": "optional-cursor-value"
  }
}

Response:

{
  "jsonrpc": "2.0",
  "id": 1,
  "result": {
    "resources": [
      {
        "uri": "file:///project/src/main.rs",
        "name": "main.rs",
        "description": "Primary application entry point",
        "mimeType": "text/x-rust"
      }
    ],
    "nextCursor": "next-page-cursor"
  }
}

Reading Resources

To retrieve resource contents, clients send a resources/read request:

Request:

{
  "jsonrpc": "2.0",
  "id": 2,
  "method": "resources/read",
  "params": {
    "uri": "file:///project/src/main.rs"
  }
}

Response:

{
  "jsonrpc": "2.0",
  "id": 2,
  "result": {
    "contents": [
      {
        "uri": "file:///project/src/main.rs",
        "mimeType": "text/x-rust",
        "text": "fn main() {\n    println!(\"Hello world!\");\n}"
      }
    ]
  }
}

Resource Templates

Resource templates allow servers to expose parameterized resources using URI templates. Arguments may be auto-completed through the completion API.

Request:

{
  "jsonrpc": "2.0",
  "id": 3,
  "method": "resources/templates/list"
}

Response:

{
  "jsonrpc": "2.0",
  "id": 3,
  "result": {
    "resourceTemplates": [
      {
        "uriTemplate": "file:///{path}",
        "name": "Project Files",
        "description": "Access files in the project directory",
        "mimeType": "application/octet-stream"
      }
    ]
  }
}

List Changed Notification

When the list of available resources changes, servers that declared the listChanged capability SHOULD send a notification:

{
  "jsonrpc": "2.0",
  "method": "notifications/resources/list_changed"
}

Subscriptions

The protocol supports optional subscriptions to resource changes. Clients can subscribe to specific resources and receive notifications when they change:

Subscribe Request:

{
  "jsonrpc": "2.0",
  "id": 4,
  "method": "resources/subscribe",
  "params": {
    "uri": "file:///project/src/main.rs"
  }
}

Update Notification:

{
  "jsonrpc": "2.0",
  "method": "notifications/resources/updated",
  "params": {
    "uri": "file:///project/src/main.rs"
  }
}

Message Flow

Server

Client

Server

Client

Resource Discovery

Resource Access

Subscriptions

Updatesresources/list

List of resources

resources/read

Resource contents

resources/subscribe

Subscription confirmed

notifications/resources/updated

resources/read

Updated contents

Data Types
Resource

A resource definition includes:

    uri: Unique identifier for the resource
    name: Human-readable name
    description: Optional description
    mimeType: Optional MIME type

Resource Contents

Resources can contain either text or binary data:
Text Content

{
  "uri": "file:///example.txt",
  "mimeType": "text/plain",
  "text": "Resource content"
}

Binary Content

{
  "uri": "file:///example.png",
  "mimeType": "image/png",
  "blob": "base64-encoded-data"
}

Common URI Schemes

The protocol defines several standard URI schemes. This list not exhaustive—implementations are always free to use additional, custom URI schemes.
https://

Used to represent a resource available on the web.

Servers SHOULD use this scheme only when the client is able to fetch and load the resource directly from the web on its own—that is, it doesn’t need to read the resource via the MCP server.

For other use cases, servers SHOULD prefer to use another URI scheme, or define a custom one, even if the server will itself be downloading resource contents over the internet.
file://

Used to identify resources that behave like a filesystem. However, the resources do not need to map to an actual physical filesystem.

MCP servers MAY identify file:// resources with an XDG MIME type, like inode/directory, to represent non-regular files (such as directories) that don’t otherwise have a standard MIME type.
git://

Git version control integration.
Error Handling

Servers SHOULD return standard JSON-RPC errors for common failure cases:

    Resource not found: -32002
    Internal errors: -32603

Example error:

{
  "jsonrpc": "2.0",
  "id": 5,
  "error": {
    "code": -32002,
    "message": "Resource not found",
    "data": {
      "uri": "file:///nonexistent.txt"
    }
  }
}

Security Considerations

    Servers MUST validate all resource URIs
    Access controls SHOULD be implemented for sensitive resources
    Binary data MUST be properly encoded
    Resource permissions SHOULD be checked before operations
	
	Tools
Protocol Revision: 2024-11-05

The Model Context Protocol (MCP) allows servers to expose tools that can be invoked by language models. Tools enable models to interact with external systems, such as querying databases, calling APIs, or performing computations. Each tool is uniquely identified by a name and includes metadata describing its schema.
User Interaction Model

Tools in MCP are designed to be model-controlled, meaning that the language model can discover and invoke tools automatically based on its contextual understanding and the user’s prompts.

However, implementations are free to expose tools through any interface pattern that suits their needs—the protocol itself does not mandate any specific user interaction model.

For trust & safety and security, there SHOULD always be a human in the loop with the ability to deny tool invocations.

Applications SHOULD:

    Provide UI that makes clear which tools are being exposed to the AI model
    Insert clear visual indicators when tools are invoked
    Present confirmation prompts to the user for operations, to ensure a human is in the loop

Capabilities

Servers that support tools MUST declare the tools capability:

{
  "capabilities": {
    "tools": {
      "listChanged": true
    }
  }
}

listChanged indicates whether the server will emit notifications when the list of available tools changes.
Protocol Messages
Listing Tools

To discover available tools, clients send a tools/list request. This operation supports pagination.

Request:

{
  "jsonrpc": "2.0",
  "id": 1,
  "method": "tools/list",
  "params": {
    "cursor": "optional-cursor-value"
  }
}

Response:

{
  "jsonrpc": "2.0",
  "id": 1,
  "result": {
    "tools": [
      {
        "name": "get_weather",
        "description": "Get current weather information for a location",
        "inputSchema": {
          "type": "object",
          "properties": {
            "location": {
              "type": "string",
              "description": "City name or zip code"
            }
          },
          "required": ["location"]
        }
      }
    ],
    "nextCursor": "next-page-cursor"
  }
}

Calling Tools

To invoke a tool, clients send a tools/call request:

Request:

{
  "jsonrpc": "2.0",
  "id": 2,
  "method": "tools/call",
  "params": {
    "name": "get_weather",
    "arguments": {
      "location": "New York"
    }
  }
}

Response:

{
  "jsonrpc": "2.0",
  "id": 2,
  "result": {
    "content": [{
      "type": "text",
      "text": "Current weather in New York:\nTemperature: 72°F\nConditions: Partly cloudy"
    }],
    "isError": false
  }
}

List Changed Notification

When the list of available tools changes, servers that declared the listChanged capability SHOULD send a notification:

{
  "jsonrpc": "2.0",
  "method": "notifications/tools/list_changed"
}

Message Flow

Server

Client

LLM

Server

Client

LLM

Discovery

Tool Selection

Invocation

Updatestools/list

List of tools

Select tool to use

tools/call

Tool result

Process result

tools/list_changed

tools/list

Updated tools

Data Types
Tool

A tool definition includes:

    name: Unique identifier for the tool
    description: Human-readable description of functionality
    inputSchema: JSON Schema defining expected parameters

Tool Result

Tool results can contain multiple content items of different types:
Text Content

{
  "type": "text",
  "text": "Tool result text"
}

Image Content

{
  "type": "image",
  "data": "base64-encoded-data",
  "mimeType": "image/png"
}

Embedded Resources

Resources MAY be embedded, to provide additional context or data, behind a URI that can be subscribed to or fetched again by the client later:

{
  "type": "resource",
  "resource": {
    "uri": "resource://example",
    "mimeType": "text/plain",
    "text": "Resource content"
  }
}

Error Handling

Tools use two error reporting mechanisms:

    Protocol Errors: Standard JSON-RPC errors for issues like:
        Unknown tools
        Invalid arguments
        Server errors

    Tool Execution Errors: Reported in tool results with isError: true:
        API failures
        Invalid input data
        Business logic errors

Example protocol error:

{
  "jsonrpc": "2.0",
  "id": 3,
  "error": {
    "code": -32602,
    "message": "Unknown tool: invalid_tool_name"
  }
}

Example tool execution error:

{
  "jsonrpc": "2.0",
  "id": 4,
  "result": {
    "content": [{
      "type": "text",
      "text": "Failed to fetch weather data: API rate limit exceeded"
    }],
    "isError": true
  }
}

Security Considerations

    Servers MUST:
        Validate all tool inputs
        Implement proper access controls
        Rate limit tool invocations
        Sanitize tool outputs

    Clients SHOULD:
        Prompt for user confirmation on sensitive operations
        Show tool inputs to the user before calling the server, to avoid malicious or accidental data exfiltration
        Validate tool results before passing to LLM
        Implement timeouts for tool calls
        Log tool usage for audit purposes
		
		
Completion
Protocol Revision: 2024-11-05

The Model Context Protocol (MCP) provides a standardized way for servers to offer argument autocompletion suggestions for prompts and resource URIs. This enables rich, IDE-like experiences where users receive contextual suggestions while entering argument values.
User Interaction Model

Completion in MCP is designed to support interactive user experiences similar to IDE code completion.

For example, applications may show completion suggestions in a dropdown or popup menu as users type, with the ability to filter and select from available options.

However, implementations are free to expose completion through any interface pattern that suits their needs—the protocol itself does not mandate any specific user interaction model.
Protocol Messages
Requesting Completions

To get completion suggestions, clients send a completion/complete request specifying what is being completed through a reference type:

Request:

{
  "jsonrpc": "2.0",
  "id": 1,
  "method": "completion/complete",
  "params": {
    "ref": {
      "type": "ref/prompt",
      "name": "code_review"
    },
    "argument": {
      "name": "language",
      "value": "py"
    }
  }
}

Response:

{
  "jsonrpc": "2.0",
  "id": 1,
  "result": {
    "completion": {
      "values": ["python", "pytorch", "pyside"],
      "total": 10,
      "hasMore": true
    }
  }
}

Reference Types

The protocol supports two types of completion references:
Type	Description	Example
ref/prompt	References a prompt by name	{"type": "ref/prompt", "name": "code_review"}
ref/resource	References a resource URI	{"type": "ref/resource", "uri": "file:///{path}"}
Completion Results

Servers return an array of completion values ranked by relevance, with:

    Maximum 100 items per response
    Optional total number of available matches
    Boolean indicating if additional results exist

Message Flow

Server

Client

Server

Client

User types argument

User continues typingcompletion/complete

Completion suggestions

completion/complete

Refined suggestions

Data Types
CompleteRequest

    ref: A PromptReference or ResourceReference
    argument: Object containing:
        name: Argument name
        value: Current value

CompleteResult

    completion: Object containing:
        values: Array of suggestions (max 100)
        total: Optional total matches
        hasMore: Additional results flag

Implementation Considerations

    Servers SHOULD:
        Return suggestions sorted by relevance
        Implement fuzzy matching where appropriate
        Rate limit completion requests
        Validate all inputs

    Clients SHOULD:
        Debounce rapid completion requests
        Cache completion results where appropriate
        Handle missing or partial results gracefully

Security

Implementations MUST:

    Validate all completion inputs
    Implement appropriate rate limiting
    Control access to sensitive suggestions
    Prevent completion-based information disclosure

Logging


Logging
Protocol Revision: 2024-11-05

The Model Context Protocol (MCP) provides a standardized way for servers to send structured log messages to clients. Clients can control logging verbosity by setting minimum log levels, with servers sending notifications containing severity levels, optional logger names, and arbitrary JSON-serializable data.
User Interaction Model

Implementations are free to expose logging through any interface pattern that suits their needs—the protocol itself does not mandate any specific user interaction model.
Capabilities

Servers that emit log message notifications MUST declare the logging capability:

{
  "capabilities": {
    "logging": {}
  }
}

Log Levels

The protocol follows the standard syslog severity levels specified in RFC 5424:
Level	Description	Example Use Case
debug	Detailed debugging information	Function entry/exit points
info	General informational messages	Operation progress updates
notice	Normal but significant events	Configuration changes
warning	Warning conditions	Deprecated feature usage
error	Error conditions	Operation failures
critical	Critical conditions	System component failures
alert	Action must be taken immediately	Data corruption detected
emergency	System is unusable	Complete system failure
Protocol Messages
Setting Log Level

To configure the minimum log level, clients MAY send a logging/setLevel request:

Request:

{
  "jsonrpc": "2.0",
  "id": 1,
  "method": "logging/setLevel",
  "params": {
    "level": "info"
  }
}

Log Message Notifications

Servers send log messages using notifications/message notifications:

{
  "jsonrpc": "2.0",
  "method": "notifications/message",
  "params": {
    "level": "error",
    "logger": "database",
    "data": {
      "error": "Connection failed",
      "details": {
        "host": "localhost",
        "port": 5432
      }
    }
  }
}

Message Flow

Server

Client

Server

Client

Configure Logging

Server Activity

Level Change

Only sends error leveland abovelogging/setLevel (info)

Empty Result

notifications/message (info)

notifications/message (warning)

notifications/message (error)

logging/setLevel (error)

Empty Result

Error Handling

Servers SHOULD return standard JSON-RPC errors for common failure cases:

    Invalid log level: -32602 (Invalid params)
    Configuration errors: -32603 (Internal error)

Implementation Considerations

    Servers SHOULD:
        Rate limit log messages
        Include relevant context in data field
        Use consistent logger names
        Remove sensitive information

    Clients MAY:
        Present log messages in the UI
        Implement log filtering/search
        Display severity visually
        Persist log messages

Security

    Log messages MUST NOT contain:
        Credentials or secrets
        Personal identifying information
        Internal system details that could aid attacks

    Implementations SHOULD:
        Rate limit messages
        Validate all data fields
        Control log access
        Monitor for sensitive content
		
		
		Pagination
Protocol Revision: 2024-11-05

The Model Context Protocol (MCP) supports paginating list operations that may return large result sets. Pagination allows servers to yield results in smaller chunks rather than all at once.

Pagination is especially important when connecting to external services over the internet, but also useful for local integrations to avoid performance issues with large data sets.
Pagination Model

Pagination in MCP uses an opaque cursor-based approach, instead of numbered pages.

    The cursor is an opaque string token, representing a position in the result set
    Page size is determined by the server, and MAY NOT be fixed

Response Format

Pagination starts when the server sends a response that includes:

    The current page of results
    An optional nextCursor field if more results exist

{
  "jsonrpc": "2.0",
  "id": "123",
  "result": {
    "resources": [...],
    "nextCursor": "eyJwYWdlIjogM30="
  }
}

Request Format

After receiving a cursor, the client can continue paginating by issuing a request including that cursor:

{
  "jsonrpc": "2.0",
  "method": "resources/list",
  "params": {
    "cursor": "eyJwYWdlIjogMn0="
  }
}

Pagination Flow

Server

Client

Server

Client

loop[Pagination Loop]List Request (no cursor)

Page of results + nextCursor

List Request (with cursor)

Operations Supporting Pagination

The following MCP operations support pagination:

    resources/list - List available resources
    resources/templates/list - List resource templates
    prompts/list - List available prompts
    tools/list - List available tools

Implementation Guidelines

    Servers SHOULD:
        Provide stable cursors
        Handle invalid cursors gracefully

    Clients SHOULD:
        Treat a missing nextCursor as the end of results
        Support both paginated and non-paginated flows

    Clients MUST treat cursors as opaque tokens:
        Don’t make assumptions about cursor format
        Don’t attempt to parse or modify cursors
        Don’t persist cursors across sessions

Error Handling

Invalid cursors SHOULD result in an error with code -32602 (Invalid params).


Roots
Protocol Revision: 2024-11-05

The Model Context Protocol (MCP) provides a standardized way for clients to expose filesystem “roots” to servers. Roots define the boundaries of where servers can operate within the filesystem, allowing them to understand which directories and files they have access to. Servers can request the list of roots from supporting clients and receive notifications when that list changes.
User Interaction Model

Roots in MCP are typically exposed through workspace or project configuration interfaces.

For example, implementations could offer a workspace/project picker that allows users to select directories and files the server should have access to. This can be combined with automatic workspace detection from version control systems or project files.

However, implementations are free to expose roots through any interface pattern that suits their needs—the protocol itself does not mandate any specific user interaction model.
Capabilities

Clients that support roots MUST declare the roots capability during initialization:

{
  "capabilities": {
    "roots": {
      "listChanged": true
    }
  }
}

listChanged indicates whether the client will emit notifications when the list of roots changes.
Protocol Messages
Listing Roots

To retrieve roots, servers send a roots/list request:

Request:

{
  "jsonrpc": "2.0",
  "id": 1,
  "method": "roots/list"
}

Response:

{
  "jsonrpc": "2.0",
  "id": 1,
  "result": {
    "roots": [
      {
        "uri": "file:///home/user/projects/myproject",
        "name": "My Project"
      }
    ]
  }
}

Root List Changes

When roots change, clients that support listChanged MUST send a notification:

{
  "jsonrpc": "2.0",
  "method": "notifications/roots/list_changed"
}

Message Flow

Client

Server

Client

Server

Discovery

Changesroots/list

Available roots

notifications/roots/list_changed

roots/list

Updated roots

Data Types
Root

A root definition includes:

    uri: Unique identifier for the root. This MUST be a file:// URI in the current specification.
    name: Optional human-readable name for display purposes.

Example roots for different use cases:
Project Directory

{
  "uri": "file:///home/user/projects/myproject",
  "name": "My Project"
}

Multiple Repositories

[
  {
    "uri": "file:///home/user/repos/frontend",
    "name": "Frontend Repository"
  },
  {
    "uri": "file:///home/user/repos/backend",
    "name": "Backend Repository"
  }
]

Error Handling

Clients SHOULD return standard JSON-RPC errors for common failure cases:

    Client does not support roots: -32601 (Method not found)
    Internal errors: -32603

Example error:

{
  "jsonrpc": "2.0",
  "id": 1,
  "error": {
    "code": -32601,
    "message": "Roots not supported",
    "data": {
      "reason": "Client does not have roots capability"
    }
  }
}

Security Considerations

    Clients MUST:
        Only expose roots with appropriate permissions
        Validate all root URIs to prevent path traversal
        Implement proper access controls
        Monitor root accessibility

    Servers SHOULD:
        Handle cases where roots become unavailable
        Respect root boundaries during operations
        Validate all paths against provided roots

Implementation Guidelines

    Clients SHOULD:
        Prompt users for consent before exposing roots to servers
        Provide clear user interfaces for root management
        Validate root accessibility before exposing
        Monitor for root changes

    Servers SHOULD:
        Check for roots capability before usage
        Handle root list changes gracefully
        Respect root boundaries in operations
        Cache root information appropriately

Sampling

Sampling
Protocol Revision: 2024-11-05

The Model Context Protocol (MCP) provides a standardized way for servers to request LLM sampling (“completions” or “generations”) from language models via clients. This flow allows clients to maintain control over model access, selection, and permissions while enabling servers to leverage AI capabilities—with no server API keys necessary. Servers can request text or image-based interactions and optionally include context from MCP servers in their prompts.
User Interaction Model

Sampling in MCP allows servers to implement agentic behaviors, by enabling LLM calls to occur nested inside other MCP server features.

Implementations are free to expose sampling through any interface pattern that suits their needs—the protocol itself does not mandate any specific user interaction model.

For trust & safety and security, there SHOULD always be a human in the loop with the ability to deny sampling requests.

Applications SHOULD:

    Provide UI that makes it easy and intuitive to review sampling requests
    Allow users to view and edit prompts before sending
    Present generated responses for review before delivery

Capabilities

Clients that support sampling MUST declare the sampling capability during initialization:

{
  "capabilities": {
    "sampling": {}
  }
}

Protocol Messages
Creating Messages

To request a language model generation, servers send a sampling/createMessage request:

Request:

{
  "jsonrpc": "2.0",
  "id": 1,
  "method": "sampling/createMessage",
  "params": {
    "messages": [
      {
        "role": "user",
        "content": {
          "type": "text",
          "text": "What is the capital of France?"
        }
      }
    ],
    "modelPreferences": {
      "hints": [
        {
          "name": "claude-3-sonnet"
        }
      ],
      "intelligencePriority": 0.8,
      "speedPriority": 0.5
    },
    "systemPrompt": "You are a helpful assistant.",
    "maxTokens": 100
  }
}

Response:

{
  "jsonrpc": "2.0",
  "id": 1,
  "result": {
    "role": "assistant",
    "content": {
      "type": "text",
      "text": "The capital of France is Paris."
    },
    "model": "claude-3-sonnet-20240307",
    "stopReason": "endTurn"
  }
}

Message Flow

LLM

User

Client

Server

LLM

User

Client

Server

Server initiates sampling

Human-in-the-loop review

Model interaction

Response review

Complete requestsampling/createMessage

Present request for approval

Review and approve/modify

Forward approved request

Return generation

Present response for approval

Review and approve/modify

Return approved response

Data Types
Messages

Sampling messages can contain:
Text Content

{
  "type": "text",
  "text": "The message content"
}

Image Content

{
  "type": "image",
  "data": "base64-encoded-image-data",
  "mimeType": "image/jpeg"
}

Model Preferences

Model selection in MCP requires careful abstraction since servers and clients may use different AI providers with distinct model offerings. A server cannot simply request a specific model by name since the client may not have access to that exact model or may prefer to use a different provider’s equivalent model.

To solve this, MCP implements a preference system that combines abstract capability priorities with optional model hints:
Capability Priorities

Servers express their needs through three normalized priority values (0-1):

    costPriority: How important is minimizing costs? Higher values prefer cheaper models.
    speedPriority: How important is low latency? Higher values prefer faster models.
    intelligencePriority: How important are advanced capabilities? Higher values prefer more capable models.

Model Hints

While priorities help select models based on characteristics, hints allow servers to suggest specific models or model families:

    Hints are treated as substrings that can match model names flexibly
    Multiple hints are evaluated in order of preference
    Clients MAY map hints to equivalent models from different providers
    Hints are advisory—clients make final model selection

For example:

{
  "hints": [
    {"name": "claude-3-sonnet"},  // Prefer Sonnet-class models
    {"name": "claude"}            // Fall back to any Claude model
  ],
  "costPriority": 0.3,            // Cost is less important
  "speedPriority": 0.8,           // Speed is very important
  "intelligencePriority": 0.5     // Moderate capability needs
}

The client processes these preferences to select an appropriate model from its available options. For instance, if the client doesn’t have access to Claude models but has Gemini, it might map the sonnet hint to gemini-1.5-pro based on similar capabilities.
Error Handling

Clients SHOULD return errors for common failure cases:

Example error:

{
  "jsonrpc": "2.0",
  "id": 1,
  "error": {
    "code": -1,
    "message": "User rejected sampling request"
  }
}

Security Considerations

    Clients SHOULD implement user approval controls
    Both parties SHOULD validate message content
    Clients SHOULD respect model preference hints
    Clients SHOULD implement rate limiting
    Both parties MUST handle sensitive data appropriately
	
	
	

	